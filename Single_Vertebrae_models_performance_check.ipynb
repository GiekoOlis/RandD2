{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Veretbrae -- Inference Pipeline for trained models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal image size: 4736 1920\n",
      "(256, 256) (128, 128) (64, 64) (32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(\"optimal image size: 4736 1920\")\n",
    "w = 256\n",
    "h = 256\n",
    "sizes = [(h, w), (h//2, w//2), (h//4, w//4), (h//8, w//8)]\n",
    "print(sizes[0], sizes[1], sizes[2], sizes[3])\n",
    "size = sizes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  6.60027588e-14],\n",
       "       [-6.59887609e-14,  1.00000000e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import matrix_power\n",
    "i = np.array([[1/2, -np.sqrt(3)/2], [np.sqrt(3)/2, 1/2]])\n",
    "matrix_power(i, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class DatasetNew(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\"image\": self.data[index]['image'], \"mask\": self.data[index]['mask']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['060_SD_C3.png',\n",
       " '060_SD_C4.png',\n",
       " '060_SD_C5.png',\n",
       " '060_SD_C6.png',\n",
       " '060_SD_C7.png',\n",
       " '060_SD_L1.png',\n",
       " '060_SD_L2.png',\n",
       " '060_SD_L3.png',\n",
       " '060_SD_L4.png',\n",
       " '060_SD_L5.png',\n",
       " '060_SD_S1.png',\n",
       " '060_SD_Th1.png',\n",
       " '060_SD_Th10.png',\n",
       " '060_SD_Th11.png',\n",
       " '060_SD_Th12.png',\n",
       " '060_SD_Th2.png',\n",
       " '060_SD_Th3.png',\n",
       " '060_SD_Th4.png',\n",
       " '060_SD_Th5.png',\n",
       " '060_SD_Th6.png',\n",
       " '060_SD_Th7.png',\n",
       " '060_SD_Th8.png',\n",
       " '060_SD_Th9.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_cases[46:69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "053_SD_C3.png\n",
      "053_SD_C4.png\n",
      "053_SD_C5.png\n",
      "053_SD_C6.png\n",
      "053_SD_C7.png\n",
      "053_SD_L1.png\n",
      "053_SD_L2.png\n",
      "053_SD_L3.png\n",
      "053_SD_L4.png\n",
      "053_SD_L5.png\n",
      "053_SD_S1.png\n",
      "053_SD_Th1.png\n",
      "053_SD_Th10.png\n",
      "053_SD_Th11.png\n",
      "053_SD_Th12.png\n",
      "053_SD_Th2.png\n",
      "053_SD_Th3.png\n",
      "053_SD_Th4.png\n",
      "053_SD_Th5.png\n",
      "053_SD_Th6.png\n",
      "053_SD_Th7.png\n",
      "053_SD_Th8.png\n",
      "053_SD_Th9.png\n",
      "057_SD_C3.png\n",
      "057_SD_C4.png\n",
      "057_SD_C5.png\n",
      "057_SD_C6.png\n",
      "057_SD_C7.png\n",
      "057_SD_L1.png\n",
      "057_SD_L2.png\n",
      "057_SD_L3.png\n",
      "057_SD_L4.png\n",
      "057_SD_L5.png\n",
      "057_SD_S1.png\n",
      "057_SD_Th1.png\n",
      "057_SD_Th10.png\n",
      "057_SD_Th11.png\n",
      "057_SD_Th12.png\n",
      "057_SD_Th2.png\n",
      "057_SD_Th3.png\n",
      "057_SD_Th4.png\n",
      "057_SD_Th5.png\n",
      "057_SD_Th6.png\n",
      "057_SD_Th7.png\n",
      "057_SD_Th8.png\n",
      "057_SD_Th9.png\n",
      "060_SD_C3.png\n",
      "060_SD_C4.png\n",
      "060_SD_C5.png\n",
      "060_SD_C6.png\n",
      "060_SD_C7.png\n",
      "060_SD_L1.png\n",
      "060_SD_L2.png\n",
      "060_SD_L3.png\n",
      "060_SD_L4.png\n",
      "060_SD_L5.png\n",
      "060_SD_S1.png\n",
      "060_SD_Th1.png\n",
      "060_SD_Th10.png\n",
      "060_SD_Th11.png\n",
      "060_SD_Th12.png\n",
      "060_SD_Th2.png\n",
      "060_SD_Th3.png\n",
      "060_SD_Th4.png\n",
      "060_SD_Th5.png\n",
      "060_SD_Th6.png\n",
      "060_SD_Th7.png\n",
      "060_SD_Th8.png\n",
      "060_SD_Th9.png\n",
      "063_SD_C3.png\n",
      "063_SD_C4.png\n",
      "063_SD_C5.png\n",
      "063_SD_C6.png\n",
      "063_SD_C7.png\n",
      "063_SD_L1.png\n",
      "063_SD_L2.png\n",
      "063_SD_L3.png\n",
      "063_SD_L4.png\n",
      "063_SD_L5.png\n",
      "063_SD_S1.png\n",
      "063_SD_Th1.png\n",
      "063_SD_Th10.png\n",
      "063_SD_Th11.png\n",
      "063_SD_Th12.png\n",
      "063_SD_Th2.png\n",
      "063_SD_Th3.png\n",
      "063_SD_Th4.png\n",
      "063_SD_Th5.png\n",
      "063_SD_Th6.png\n",
      "063_SD_Th7.png\n",
      "063_SD_Th8.png\n",
      "063_SD_Th9.png\n",
      "073_SD_C3.png\n",
      "073_SD_C4.png\n",
      "073_SD_C5.png\n",
      "073_SD_C6.png\n",
      "073_SD_C7.png\n",
      "073_SD_L1.png\n",
      "073_SD_L2.png\n",
      "073_SD_L3.png\n",
      "073_SD_L4.png\n",
      "073_SD_L5.png\n",
      "073_SD_S1.png\n",
      "073_SD_Th1.png\n",
      "073_SD_Th10.png\n",
      "073_SD_Th11.png\n",
      "073_SD_Th12.png\n",
      "073_SD_Th2.png\n",
      "073_SD_Th3.png\n",
      "073_SD_Th4.png\n",
      "073_SD_Th5.png\n",
      "073_SD_Th6.png\n",
      "073_SD_Th7.png\n",
      "073_SD_Th8.png\n",
      "073_SD_Th9.png\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from functionality import *\n",
    "\n",
    "path_to_dataset = \"C:\\\\Users\\\\gieko\\\\Dropbox\\\\NIITO_Vertebrae\\\\NIITO_Vertebrae_Dataset\\\\NIITO_Vertebrae_Dataset_Final_Test_resized\\\\data_single_vertebra\"\n",
    "#  \"C:\\Users\\EUgolnikova\\Dropbox\\NIITO_Vertebrae\\NIITO_Vertebrae_Dataset\\NIITO_Vertebrae_Dataset_Test\"\n",
    "\n",
    "path_to_images = os.path.join(path_to_dataset, \"images\")\n",
    "path_to_labels = os.path.join(path_to_dataset, \"labels\")\n",
    "\n",
    "test_cases = os.listdir(path_to_images)\n",
    "\n",
    "test_transforms = A.ReplayCompose(\n",
    "    [   \n",
    "        A.Resize(height=size[0], width=size[1]),\n",
    "        ToTensorV2()\n",
    "    ],\n",
    "    additional_targets={'image': 'image', 'mask': 'mask'})\n",
    "\n",
    "\n",
    "\n",
    "test_aug = []\n",
    "for case in test_cases:\n",
    "    print(case)\n",
    "    path_mask = os.path.join(path_to_labels, case)\n",
    "    path_image = os.path.join(path_to_images, case)\n",
    "    \n",
    "    image = cv2.imread(path_image, 1)\n",
    "    # mask = read_mask(path_mask)\n",
    "    mask = cv2.imread(path_mask, 0)   \n",
    "    mask[mask==255] = 1.0 \n",
    "    # print(image.shape, mask.shape)\n",
    "\n",
    "    # image = np.moveaxis(image, 0, 2)\n",
    "\n",
    "    \n",
    "    augmentations = test_transforms(image=image, mask=mask)\n",
    "    # print(\"!!\",augmentations['image'].shape, augmentations['mask'].shape)\n",
    "\n",
    "    test_aug.append({\n",
    "        \"image\": augmentations['image'],\n",
    "        \"mask\": augmentations['mask']\n",
    "    })\n",
    "\n",
    "\n",
    "test_dataset = DatasetNew(test_aug)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, pin_memory=True, shuffle=True)\n",
    "\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(loader):\n",
    "    ch_sum, ch_squared_sum, count_of_batches = 0, 0, 0\n",
    "    \n",
    "    for data in loader:\n",
    "        data = data['image'].float()\n",
    "        data /= 255        \n",
    "\n",
    "        ch_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        ch_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
    "        count_of_batches += 1\n",
    "\n",
    "    mean = ch_sum / count_of_batches \n",
    "    std = (ch_squared_sum / count_of_batches - mean**2)**0.5\n",
    "\n",
    "    return mean, std \n",
    "\n",
    "\n",
    "def soft_dice(*, y_true, y_pred):\n",
    "    eps = 1e-15\n",
    "    y_pred = y_pred.contiguous().view(y_pred.numel())\n",
    "    y_true = y_true.contiguous().view(y_true.numel())\n",
    "    intersection = (y_pred * y_true).sum(0)\n",
    "    scores = 2. * (intersection + eps) / (y_pred.sum(0) + y_true.sum(0) + eps)\n",
    "    score = scores.sum() / scores.numel()\n",
    "    \n",
    "    return torch.clamp(score, 0., 1.)\n",
    "\n",
    "\n",
    "def hard_dice(*, y_true, y_pred, thr=0.5):\n",
    "    y_pred = (y_pred > thr).float()\n",
    "    return soft_dice(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred, thr=0.5):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    \n",
    "    y_pred = (y_pred > thr).float()\n",
    "    num_correct += (y_true == y_pred).sum()\n",
    "    num_pixels += torch.numel(y_pred)\n",
    "    \n",
    "    return num_correct/num_pixels*100\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import skimage\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def read_mask(mask_name):\n",
    "    mask = (skimage.io.imread(mask_name)[:,:]==255).astype(np.uint8)*255\n",
    "    mask = (mask > 0).astype(np.uint8)\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "def make_blending(img_path, mask_path, alpha=0.5):\n",
    "    img, mask = read_mask(img_path), read_mask(mask_path)[:, :, 0]\n",
    "    colors = np.array([[0,0,0], [255,0,0]], np.uint8)\n",
    "    return (img*alpha + colors[mask.astype(np.int32)]*(1. - alpha)).astype(np.uint8)\n",
    "\n",
    "\n",
    "def show_images_with_mask(image_path,  mask_path_fill, alpha=0.5):\n",
    "    plt.figure(figsize=(20, 14))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    orig, _m = read_mask(image_path), read_mask(mask_path_fill)\n",
    "    plt.imshow(orig)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    blend = make_blending(image_path, mask_path_fill, alpha)\n",
    "    plt.imshow(blend)\n",
    "\n",
    "\n",
    "def save_predictions_as_imgs(loader, model, thr=0.5, folder=\"/content/saved_images\", device='cpu'):\n",
    "  if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "  model.to(device=device).eval()\n",
    "#   model.eval()\n",
    "  acc = []\n",
    "  s_dice = []\n",
    "  h_dice = []\n",
    "  times = []\n",
    "  y_trues = []\n",
    "  y_preds = []\n",
    "  for idx, data in enumerate(loader):\n",
    "\n",
    "    x = img = data['image'].float().to(device=device)\n",
    "    img = torch.squeeze(img, 0)\n",
    "    img = img.permute(1, 2, 0)\n",
    "    y = mask = data['mask'].to(device=device)\n",
    "    mask = torch.squeeze(mask, 0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      start_time= time.time() \n",
    "      preds = torch.sigmoid(model(x))\n",
    "      preds = (preds > thr).float()\n",
    "      stop_time=time.time()\n",
    "\n",
    "    duration =stop_time - start_time\n",
    "    hours = duration // 3600\n",
    "    minutes = (duration - (hours * 3600)) // 60\n",
    "    seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "    msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
    "    times.append(duration)\n",
    "\n",
    "    x = x.float() / 255\n",
    "    # print(type(x), type(preds))\n",
    "    # print(y.shape, preds.shape)\n",
    "    # y_trues = torch.cat((y_trues, y), 0)\n",
    "    # y_preds = torch.cat((y_preds, preds), 0)\n",
    "    y_trues.append(y)\n",
    "    y_preds.append(preds)\n",
    "    acc.append(accuracy(y, preds))\n",
    "    h_dice.append(hard_dice(y_true=y, y_pred=preds))\n",
    "    s_dice.append(soft_dice(y_true=y, y_pred=preds))\n",
    "\n",
    "    torchvision.utils.save_image(x, f\"{folder}/orig_{idx}.png\")\n",
    "    torchvision.utils.save_image(preds, f\"{folder}/pred_{idx}.png\")\n",
    "    torchvision.utils.save_image(y.float(), f\"{folder}/gt_{idx}.png\")\n",
    "    # torchvision.utils.save_image(y, f\"{folder}/{idx}.png\")\n",
    "  \n",
    "  # sum_true = sum(y_trues)\n",
    "  # sum_preds = sum(y_preds)\n",
    "  dice_per_case = hard_dice(y_true=torch.cat(y_trues), y_pred=torch.cat(y_preds))\n",
    "  means = [np.mean(acc), np.mean(s_dice), np.mean(h_dice), np.mean(times)]\n",
    "  return {\"accuracy\": acc, \"soft DICE\": s_dice, \"DICE\": h_dice, \"time\": times, \"means\": means, \"dice per case\": dice_per_case} \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_blended(path_to_folder, number_of_images, acc = None, s_dice = None, h_dice = None, alpha = 0.75, beta = 0.95):\n",
    "\n",
    "    for k in range(number_of_images):\n",
    "        path_img = os.path.join(path_to_folder, \"orig_\" + str(k) + \".png\")\n",
    "        path_mask = os.path.join(path_to_folder, \"pred_\" + str(k) + \".png\")\n",
    "        path_mask_gt = os.path.join(path_to_folder, \"gt_\" + str(k) + \".png\")\n",
    "        path_save = os.path.join(path_to_folder, \"blend_\" + str(k) + \".png\")\n",
    "\n",
    "        img = plt.imread(path_img)\n",
    "        msk = plt.imread(path_mask)\n",
    "        msk_gt = plt.imread(path_mask_gt)\n",
    "\n",
    "        red  = np.array([1,0,0],dtype=np.uint8)\n",
    "        blue = np.array([0,0,1],dtype=np.uint8)\n",
    "\n",
    "        # print(accuracy(img, msk))\n",
    "        # print(hard_dice(y_true=img, y_pred=msk))\n",
    "        # print(soft_dice(y_true=img, y_pred=msk))\n",
    "\n",
    "        # plt.figure(figsize=(20, 14))\n",
    "        # plt.subplot(1, 3, 1)\n",
    "        # plt.imshow(img)\n",
    "        # plt.subplot(1, 3, 2)\n",
    "        # plt.imshow(msk)\n",
    "\n",
    "        # print(img.shape, msk.shape)\n",
    "        for i in range(msk.shape[0]):\n",
    "            for j in range(msk.shape[1]):\n",
    "                if msk[i, j].all() == 1:\n",
    "                    msk[i, j] = red\n",
    "                if msk_gt[i, j].all() == 1:\n",
    "                    msk_gt[i, j] = blue\n",
    "\n",
    "        # for i in range(msk.shape[0]):\n",
    "        #     for j in range(msk.shape[1]):\n",
    "        #         if msk[i, j].all() == 1:\n",
    "        #             msk[i, j] = red\n",
    "                \n",
    "\n",
    "        res = (img*alpha + msk*(1 - alpha))\n",
    "        res = (res*beta + msk_gt*(1 - beta))\n",
    "\n",
    "\n",
    "        # plt.subplot(1, 3, 3)\n",
    "        # plt.imshow(res)\n",
    "\n",
    "\n",
    "        res = (res * 255).astype(np.uint8)\n",
    "\n",
    "        im = Image.fromarray(res)\n",
    "\n",
    "        str_ = \"\"\n",
    "        str_ += f\"\\n accuracy: {acc[k]}\" if acc is not None else \"\"\n",
    "        str_ += f\"\\n DICE: {h_dice[k]}\" if h_dice is not None else \"\"\n",
    "\n",
    "        # print(str_)\n",
    "        font = ImageFont.truetype('arial', size=16)\n",
    "        ImageDraw.Draw(\n",
    "            im  # Image\n",
    "        ).text(\n",
    "            (0, 0),  # Coordinates\n",
    "            str_,  # Text\n",
    "            (255, 185, 93),  # Color\n",
    "            font\n",
    "        )\n",
    "\n",
    "\n",
    "        im.save(path_save)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvLRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False)\n",
    "        self.batchNorm = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchNorm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class DoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            ConvLRelu(in_channels, out_channels),\n",
    "            ConvLRelu(out_channels, out_channels),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.conv_block = DoubleConvBlock(in_channels, out_channels)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        before_pool = self.conv_block(x)\n",
    "        x = self.max_pool(before_pool)\n",
    "        return x, before_pool\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DecoderBlock, self).__init__()              \n",
    "        self.conv_block = DoubleConvBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        return self.conv_block(torch.cat([x, y], dim=1))\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, n_filters=64):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.enc1 = EncoderBlock(in_channels, n_filters)\n",
    "        self.enc2 = EncoderBlock(n_filters, n_filters * 2)\n",
    "        self.enc3 = EncoderBlock(n_filters * 2, n_filters * 4)\n",
    "        self.enc4 = EncoderBlock(n_filters * 4, n_filters * 8)\n",
    "        \n",
    "        self.center = DoubleConvBlock(n_filters * 8, n_filters * 16)\n",
    "        \n",
    "        self.dec4 = DecoderBlock(n_filters * (16 + 8), n_filters * 8)\n",
    "        self.dec3 = DecoderBlock(n_filters * (8 + 4), n_filters * 4)\n",
    "        self.dec2 = DecoderBlock(n_filters * (4 + 2), n_filters * 2)\n",
    "        self.dec1 = DecoderBlock(n_filters * (2 + 1), n_filters)\n",
    "\n",
    "        self.final = nn.Conv2d(n_filters, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x, enc1 = self.enc1(x)\n",
    "        x, enc2 = self.enc2(x)\n",
    "        x, enc3 = self.enc3(x)\n",
    "        x, enc4 = self.enc4(x)\n",
    "\n",
    "        center = self.center(x)\n",
    "\n",
    "        dec4 = self.dec4(center, enc4)\n",
    "        dec3 = self.dec3(dec4, enc3)\n",
    "        dec2 = self.dec2(dec3, enc2)\n",
    "        dec1 = self.dec1(dec2, enc1)\n",
    "\n",
    "        \n",
    "        final = self.final(dec1)\n",
    "\n",
    "        return final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jolly Wind 17\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "tensor(0.9491)\n"
     ]
    }
   ],
   "source": [
    "hyperparametrs = {\n",
    "    'n_filters': 32,\n",
    "    'loss_weight': 0.8,\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 50,\n",
    "    'lr_reduce_rate': 0.5,\n",
    "    'patience': 4,\n",
    "    'early_stopping': 50, # пока уберем раннюю остановку\n",
    "    'model': 'test'\n",
    "}\n",
    "model = UNet(n_filters=hyperparametrs['n_filters'])\n",
    "model.load_state_dict(torch.load('C:/Users/gieko/Dropbox/NIITO_Vertebrae/Scripts/weight/UNet_single-vertebrae/jolly-wind-17/weights.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "folder = 'C:/Users/gieko/Dropbox/NIITO_Vertebrae/Scripts/inference/UNet_single-vertebrae/jolly-wind-17/'\n",
    "print(\"model loaded\")\n",
    "metrics = save_predictions_as_imgs(test_loader, model, folder = folder)\n",
    "print(metrics[\"dice per case\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_blended(path_to_folder=folder, number_of_images=115, acc = metrics['accuracy'], h_dice = metrics['DICE'], alpha = 0.75, beta = 0.8)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upbeat Tree 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "tensor(0.9429)\n"
     ]
    }
   ],
   "source": [
    "hyperparametrs = {\n",
    "    'n_filters': 32,\n",
    "    'loss_weight': 0.8,\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 50,\n",
    "    'lr_reduce_rate': 0.5,\n",
    "    'patience': 4,\n",
    "    'early_stopping': 50, # пока уберем раннюю остановку\n",
    "    'model': 'test'\n",
    "}\n",
    "model = UNet(n_filters=hyperparametrs['n_filters'])\n",
    "model.load_state_dict(torch.load('C:/Users/gieko/Dropbox/NIITO_Vertebrae/Scripts/weight/UNet_single-vertebrae/upbeat-tree-20/weights.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "folder = 'C:/Users/gieko/Dropbox/NIITO_Vertebrae/Scripts/inference/UNet_single-vertebrae/upbeat-tree-20/'\n",
    "print(\"model loaded\")\n",
    "metrics = save_predictions_as_imgs(test_loader, model, folder = folder)\n",
    "print(metrics[\"dice per case\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_blended(path_to_folder=folder, number_of_images=115, acc = metrics['accuracy'], h_dice = metrics['DICE'], alpha = 0.75, beta = 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [tensor(97.1207),\n",
       "  tensor(95.7474),\n",
       "  tensor(97.5525),\n",
       "  tensor(93.8568),\n",
       "  tensor(94.7937),\n",
       "  tensor(96.9269),\n",
       "  tensor(96.8979),\n",
       "  tensor(95.3522),\n",
       "  tensor(97.2672),\n",
       "  tensor(95.9946),\n",
       "  tensor(90.9210),\n",
       "  tensor(95.7245),\n",
       "  tensor(91.6199),\n",
       "  tensor(91.7175),\n",
       "  tensor(91.5054),\n",
       "  tensor(96.2555),\n",
       "  tensor(93.2007),\n",
       "  tensor(85.8215),\n",
       "  tensor(96.4813),\n",
       "  tensor(97.0474),\n",
       "  tensor(97.3038),\n",
       "  tensor(95.1508),\n",
       "  tensor(98.2178),\n",
       "  tensor(96.6141),\n",
       "  tensor(94.3298),\n",
       "  tensor(95.4163),\n",
       "  tensor(90.4602),\n",
       "  tensor(93.5593),\n",
       "  tensor(96.9788),\n",
       "  tensor(94.7845),\n",
       "  tensor(93.8110),\n",
       "  tensor(87.9272),\n",
       "  tensor(94.7113),\n",
       "  tensor(94.3893),\n",
       "  tensor(96.0220),\n",
       "  tensor(96.4188),\n",
       "  tensor(97.2168),\n",
       "  tensor(95.4224),\n",
       "  tensor(97.6593),\n",
       "  tensor(91.0889),\n",
       "  tensor(95.6207),\n",
       "  tensor(97.3663),\n",
       "  tensor(96.1639),\n",
       "  tensor(92.2684),\n",
       "  tensor(97.9980),\n",
       "  tensor(96.8933),\n",
       "  tensor(96.5790),\n",
       "  tensor(95.1645),\n",
       "  tensor(94.1605),\n",
       "  tensor(96.3837),\n",
       "  tensor(97.6120),\n",
       "  tensor(91.5909),\n",
       "  tensor(94.9615),\n",
       "  tensor(96.6736),\n",
       "  tensor(95.4178),\n",
       "  tensor(96.1945),\n",
       "  tensor(97.0184),\n",
       "  tensor(95.0958),\n",
       "  tensor(93.2785),\n",
       "  tensor(95.8145),\n",
       "  tensor(95.8694),\n",
       "  tensor(97.0932),\n",
       "  tensor(96.7102),\n",
       "  tensor(95.7855),\n",
       "  tensor(93.0176),\n",
       "  tensor(91.9708),\n",
       "  tensor(93.7637),\n",
       "  tensor(89.1922),\n",
       "  tensor(96.0434),\n",
       "  tensor(95.6696),\n",
       "  tensor(91.6214),\n",
       "  tensor(97.2778),\n",
       "  tensor(96.7072),\n",
       "  tensor(94.8685),\n",
       "  tensor(98.1110),\n",
       "  tensor(95.9229),\n",
       "  tensor(97.7081),\n",
       "  tensor(92.5156),\n",
       "  tensor(94.3390),\n",
       "  tensor(92.3904),\n",
       "  tensor(95.5627),\n",
       "  tensor(98.2056),\n",
       "  tensor(93.7958),\n",
       "  tensor(96.7941),\n",
       "  tensor(93.4372),\n",
       "  tensor(94.5831),\n",
       "  tensor(97.1329),\n",
       "  tensor(95.9686),\n",
       "  tensor(93.6844),\n",
       "  tensor(98.0164),\n",
       "  tensor(97.2763),\n",
       "  tensor(96.1685),\n",
       "  tensor(93.5089),\n",
       "  tensor(96.2250),\n",
       "  tensor(96.7331),\n",
       "  tensor(95.4361),\n",
       "  tensor(95.1599),\n",
       "  tensor(97.6273),\n",
       "  tensor(89.8926),\n",
       "  tensor(96.7880),\n",
       "  tensor(95.5414),\n",
       "  tensor(91.7114),\n",
       "  tensor(93.9316),\n",
       "  tensor(90.8157),\n",
       "  tensor(94.1391),\n",
       "  tensor(95.3308),\n",
       "  tensor(89.2456),\n",
       "  tensor(93.0435),\n",
       "  tensor(93.4326),\n",
       "  tensor(95.5429),\n",
       "  tensor(94.9509),\n",
       "  tensor(96.2555),\n",
       "  tensor(95.5200),\n",
       "  tensor(89.9200),\n",
       "  tensor(97.1985)],\n",
       " 'soft DICE': [tensor(0.9685),\n",
       "  tensor(0.9566),\n",
       "  tensor(0.9776),\n",
       "  tensor(0.9302),\n",
       "  tensor(0.9364),\n",
       "  tensor(0.9699),\n",
       "  tensor(0.9670),\n",
       "  tensor(0.9552),\n",
       "  tensor(0.9674),\n",
       "  tensor(0.9578),\n",
       "  tensor(0.8907),\n",
       "  tensor(0.9507),\n",
       "  tensor(0.8973),\n",
       "  tensor(0.8917),\n",
       "  tensor(0.8917),\n",
       "  tensor(0.9457),\n",
       "  tensor(0.9107),\n",
       "  tensor(0.8402),\n",
       "  tensor(0.9708),\n",
       "  tensor(0.9663),\n",
       "  tensor(0.9724),\n",
       "  tensor(0.9448),\n",
       "  tensor(0.9728),\n",
       "  tensor(0.9649),\n",
       "  tensor(0.9378),\n",
       "  tensor(0.9465),\n",
       "  tensor(0.8781),\n",
       "  tensor(0.9098),\n",
       "  tensor(0.9676),\n",
       "  tensor(0.9274),\n",
       "  tensor(0.9157),\n",
       "  tensor(0.8542),\n",
       "  tensor(0.9297),\n",
       "  tensor(0.9415),\n",
       "  tensor(0.9340),\n",
       "  tensor(0.9635),\n",
       "  tensor(0.9689),\n",
       "  tensor(0.9610),\n",
       "  tensor(0.9674),\n",
       "  tensor(0.8909),\n",
       "  tensor(0.9482),\n",
       "  tensor(0.9781),\n",
       "  tensor(0.9611),\n",
       "  tensor(0.8908),\n",
       "  tensor(0.9788),\n",
       "  tensor(0.9687),\n",
       "  tensor(0.9709),\n",
       "  tensor(0.9543),\n",
       "  tensor(0.9509),\n",
       "  tensor(0.9626),\n",
       "  tensor(0.9766),\n",
       "  tensor(0.8955),\n",
       "  tensor(0.9469),\n",
       "  tensor(0.9558),\n",
       "  tensor(0.9424),\n",
       "  tensor(0.9362),\n",
       "  tensor(0.9687),\n",
       "  tensor(0.9414),\n",
       "  tensor(0.9077),\n",
       "  tensor(0.9633),\n",
       "  tensor(0.9455),\n",
       "  tensor(0.9676),\n",
       "  tensor(0.9678),\n",
       "  tensor(0.9613),\n",
       "  tensor(0.9292),\n",
       "  tensor(0.8969),\n",
       "  tensor(0.9387),\n",
       "  tensor(0.8754),\n",
       "  tensor(0.9467),\n",
       "  tensor(0.9638),\n",
       "  tensor(0.8986),\n",
       "  tensor(0.9678),\n",
       "  tensor(0.9647),\n",
       "  tensor(0.9210),\n",
       "  tensor(0.9783),\n",
       "  tensor(0.9565),\n",
       "  tensor(0.9720),\n",
       "  tensor(0.9164),\n",
       "  tensor(0.9434),\n",
       "  tensor(0.9316),\n",
       "  tensor(0.9559),\n",
       "  tensor(0.9794),\n",
       "  tensor(0.9233),\n",
       "  tensor(0.9718),\n",
       "  tensor(0.9216),\n",
       "  tensor(0.9344),\n",
       "  tensor(0.9667),\n",
       "  tensor(0.9653),\n",
       "  tensor(0.8955),\n",
       "  tensor(0.9790),\n",
       "  tensor(0.9681),\n",
       "  tensor(0.9522),\n",
       "  tensor(0.9318),\n",
       "  tensor(0.9519),\n",
       "  tensor(0.9663),\n",
       "  tensor(0.9454),\n",
       "  tensor(0.9364),\n",
       "  tensor(0.9712),\n",
       "  tensor(0.8582),\n",
       "  tensor(0.9655),\n",
       "  tensor(0.9359),\n",
       "  tensor(0.8929),\n",
       "  tensor(0.9015),\n",
       "  tensor(0.8830),\n",
       "  tensor(0.9399),\n",
       "  tensor(0.9278),\n",
       "  tensor(0.8513),\n",
       "  tensor(0.9181),\n",
       "  tensor(0.9183),\n",
       "  tensor(0.9590),\n",
       "  tensor(0.9489),\n",
       "  tensor(0.9627),\n",
       "  tensor(0.9567),\n",
       "  tensor(0.8722),\n",
       "  tensor(0.9749)],\n",
       " 'DICE': [tensor(0.9685),\n",
       "  tensor(0.9566),\n",
       "  tensor(0.9776),\n",
       "  tensor(0.9302),\n",
       "  tensor(0.9364),\n",
       "  tensor(0.9699),\n",
       "  tensor(0.9670),\n",
       "  tensor(0.9552),\n",
       "  tensor(0.9674),\n",
       "  tensor(0.9578),\n",
       "  tensor(0.8907),\n",
       "  tensor(0.9507),\n",
       "  tensor(0.8973),\n",
       "  tensor(0.8917),\n",
       "  tensor(0.8917),\n",
       "  tensor(0.9457),\n",
       "  tensor(0.9107),\n",
       "  tensor(0.8402),\n",
       "  tensor(0.9708),\n",
       "  tensor(0.9663),\n",
       "  tensor(0.9724),\n",
       "  tensor(0.9448),\n",
       "  tensor(0.9728),\n",
       "  tensor(0.9649),\n",
       "  tensor(0.9378),\n",
       "  tensor(0.9465),\n",
       "  tensor(0.8781),\n",
       "  tensor(0.9098),\n",
       "  tensor(0.9676),\n",
       "  tensor(0.9274),\n",
       "  tensor(0.9157),\n",
       "  tensor(0.8542),\n",
       "  tensor(0.9297),\n",
       "  tensor(0.9415),\n",
       "  tensor(0.9340),\n",
       "  tensor(0.9635),\n",
       "  tensor(0.9689),\n",
       "  tensor(0.9610),\n",
       "  tensor(0.9674),\n",
       "  tensor(0.8909),\n",
       "  tensor(0.9482),\n",
       "  tensor(0.9781),\n",
       "  tensor(0.9611),\n",
       "  tensor(0.8908),\n",
       "  tensor(0.9788),\n",
       "  tensor(0.9687),\n",
       "  tensor(0.9709),\n",
       "  tensor(0.9543),\n",
       "  tensor(0.9509),\n",
       "  tensor(0.9626),\n",
       "  tensor(0.9766),\n",
       "  tensor(0.8955),\n",
       "  tensor(0.9469),\n",
       "  tensor(0.9558),\n",
       "  tensor(0.9424),\n",
       "  tensor(0.9362),\n",
       "  tensor(0.9687),\n",
       "  tensor(0.9414),\n",
       "  tensor(0.9077),\n",
       "  tensor(0.9633),\n",
       "  tensor(0.9455),\n",
       "  tensor(0.9676),\n",
       "  tensor(0.9678),\n",
       "  tensor(0.9613),\n",
       "  tensor(0.9292),\n",
       "  tensor(0.8969),\n",
       "  tensor(0.9387),\n",
       "  tensor(0.8754),\n",
       "  tensor(0.9467),\n",
       "  tensor(0.9638),\n",
       "  tensor(0.8986),\n",
       "  tensor(0.9678),\n",
       "  tensor(0.9647),\n",
       "  tensor(0.9210),\n",
       "  tensor(0.9783),\n",
       "  tensor(0.9565),\n",
       "  tensor(0.9720),\n",
       "  tensor(0.9164),\n",
       "  tensor(0.9434),\n",
       "  tensor(0.9316),\n",
       "  tensor(0.9559),\n",
       "  tensor(0.9794),\n",
       "  tensor(0.9233),\n",
       "  tensor(0.9718),\n",
       "  tensor(0.9216),\n",
       "  tensor(0.9344),\n",
       "  tensor(0.9667),\n",
       "  tensor(0.9653),\n",
       "  tensor(0.8955),\n",
       "  tensor(0.9790),\n",
       "  tensor(0.9681),\n",
       "  tensor(0.9522),\n",
       "  tensor(0.9318),\n",
       "  tensor(0.9519),\n",
       "  tensor(0.9663),\n",
       "  tensor(0.9454),\n",
       "  tensor(0.9364),\n",
       "  tensor(0.9712),\n",
       "  tensor(0.8582),\n",
       "  tensor(0.9655),\n",
       "  tensor(0.9359),\n",
       "  tensor(0.8929),\n",
       "  tensor(0.9015),\n",
       "  tensor(0.8830),\n",
       "  tensor(0.9399),\n",
       "  tensor(0.9278),\n",
       "  tensor(0.8513),\n",
       "  tensor(0.9181),\n",
       "  tensor(0.9183),\n",
       "  tensor(0.9590),\n",
       "  tensor(0.9489),\n",
       "  tensor(0.9627),\n",
       "  tensor(0.9567),\n",
       "  tensor(0.8722),\n",
       "  tensor(0.9749)],\n",
       " 'time': [0.29152584075927734,\n",
       "  0.27979087829589844,\n",
       "  0.2998168468475342,\n",
       "  0.3063170909881592,\n",
       "  0.25400805473327637,\n",
       "  0.2780425548553467,\n",
       "  0.298168420791626,\n",
       "  0.26909875869750977,\n",
       "  0.2940549850463867,\n",
       "  0.34999799728393555,\n",
       "  0.2728424072265625,\n",
       "  0.2599070072174072,\n",
       "  0.3169987201690674,\n",
       "  0.2865011692047119,\n",
       "  0.33185839653015137,\n",
       "  0.4387028217315674,\n",
       "  0.2973487377166748,\n",
       "  0.26799893379211426,\n",
       "  0.3308827877044678,\n",
       "  0.2760775089263916,\n",
       "  0.2709980010986328,\n",
       "  0.3074791431427002,\n",
       "  0.2629997730255127,\n",
       "  0.26844072341918945,\n",
       "  0.2989993095397949,\n",
       "  0.32399654388427734,\n",
       "  0.37511658668518066,\n",
       "  0.39163851737976074,\n",
       "  0.3831362724304199,\n",
       "  0.3749995231628418,\n",
       "  0.40012145042419434,\n",
       "  0.3789992332458496,\n",
       "  0.3363943099975586,\n",
       "  0.28728294372558594,\n",
       "  0.3844797611236572,\n",
       "  0.3653709888458252,\n",
       "  0.3997771739959717,\n",
       "  0.3785288333892822,\n",
       "  0.32477736473083496,\n",
       "  0.34381580352783203,\n",
       "  0.3442988395690918,\n",
       "  0.42926931381225586,\n",
       "  0.3309600353240967,\n",
       "  0.31428098678588867,\n",
       "  0.3469994068145752,\n",
       "  0.3972632884979248,\n",
       "  0.3580443859100342,\n",
       "  0.40122032165527344,\n",
       "  0.30736255645751953,\n",
       "  0.3322484493255615,\n",
       "  0.3249995708465576,\n",
       "  0.29587459564208984,\n",
       "  0.3584473133087158,\n",
       "  0.2609984874725342,\n",
       "  0.37864065170288086,\n",
       "  0.34511280059814453,\n",
       "  0.318889856338501,\n",
       "  0.34360790252685547,\n",
       "  0.2964930534362793,\n",
       "  0.32793688774108887,\n",
       "  0.34000372886657715,\n",
       "  0.3426995277404785,\n",
       "  0.33399081230163574,\n",
       "  0.38808250427246094,\n",
       "  0.31299901008605957,\n",
       "  0.2997720241546631,\n",
       "  0.32581162452697754,\n",
       "  0.3241746425628662,\n",
       "  0.378617525100708,\n",
       "  0.31999874114990234,\n",
       "  0.35173535346984863,\n",
       "  0.32399892807006836,\n",
       "  0.37865209579467773,\n",
       "  0.3531064987182617,\n",
       "  0.3269996643066406,\n",
       "  0.3236539363861084,\n",
       "  0.29613518714904785,\n",
       "  0.32280969619750977,\n",
       "  0.33151769638061523,\n",
       "  0.36042165756225586,\n",
       "  0.3241550922393799,\n",
       "  0.35899853706359863,\n",
       "  0.42292141914367676,\n",
       "  0.41285133361816406,\n",
       "  0.3429853916168213,\n",
       "  0.29803466796875,\n",
       "  0.31519198417663574,\n",
       "  0.3746025562286377,\n",
       "  0.3336930274963379,\n",
       "  0.408998966217041,\n",
       "  0.3345620632171631,\n",
       "  0.29640769958496094,\n",
       "  0.3896372318267822,\n",
       "  0.32163310050964355,\n",
       "  0.33299970626831055,\n",
       "  0.365250825881958,\n",
       "  0.3373990058898926,\n",
       "  0.4165651798248291,\n",
       "  0.3438420295715332,\n",
       "  0.36562442779541016,\n",
       "  0.4146151542663574,\n",
       "  0.31992101669311523,\n",
       "  0.3783080577850342,\n",
       "  0.3647298812866211,\n",
       "  0.3399994373321533,\n",
       "  0.3429701328277588,\n",
       "  0.35317039489746094,\n",
       "  0.35820579528808594,\n",
       "  0.34146785736083984,\n",
       "  0.35899949073791504,\n",
       "  0.3640158176422119,\n",
       "  0.3659999370574951,\n",
       "  0.38996148109436035,\n",
       "  0.38183116912841797,\n",
       "  0.4395143985748291],\n",
       " 'means': [94.92778, 0.94014496, 0.94014496, 0.3392650956692903],\n",
       " 'dice per case': tensor(0.9429)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:/Users/gieko/Dropbox/NIITO_Vertebrae/Scripts/inference/UNet_spinal-cord/apricot-water-43\"\n",
    "save_blended(path_to_folder=folder, number_of_images=5, acc = metrics['accuracy'], h_dice = metrics['DICE'], alpha = 0.75, beta = 0.8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "384b21feacb641c3e0314271197cb6efcbf5df7640640373c033a2a56e65c0f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
